# Exercise 4: Playing with Great Expectations

Welcome to the fifth exercise of our ETL Testing Framework tutorial! In this exercise, you'll learn how to implement a new data source for the clean bucket, add expectations for the data sources, and build and run checkpoints to ensure data quality.

## Table of Contents
1. [Overview](#overview)
2. [Prerequisites](#prerequisites)
3. [Setting up the new data source](#setting-up-the-new-data-source)
4. [Adding expectations for data sources](#adding-expectations-for-data-sources)
5. [Building and running checkpoints](#building-and-running-checkpoints)
6. [Common Issues and Tips](#common-issues-and-tips)
7. [Next Steps](#next-steps)

## Exercise 4 Checklist

Use this checklist to ensure you've completed all the necessary steps for Exercise 5:

- [ ] Implement a new data source for the clean bucket
- [ ] Add expectations for the new data source
- [ ] Build and run checkpoints to validate data quality

Once you've checked off all these items, you've successfully completed Exercise 5!

## Prerequisites
Before you begin, make sure you have completed Exercise 4 and have the following:
- Access to the clean bucket in your AWS S3
- Basic understanding of data validation and expectations

## Configuring Environment Variables
To run the Great Expectations scripts, you need to configure several environment variables. Create a `.env` file in the `tests/` folder of your project directory and add the following variables:

```bash
touch tests/.env
```
Then, open the `.env` file and add the following content using the resources on aws, you will find them on the resource group:

```
RAW_BUCKET=your_raw_bucket_name
CLEAN_BUCKET=your_clean_bucket_name
CURATED_BUCKET=your_curated_bucket_name
GX_REPORT_BUCKET=your_report_bucket_name  # Optional: for storing data docs
S3_ENDPOINT=https://s3.your-region.amazonaws.com  # Optional: specify if using a custom endpoint
```

Replace `your_raw_bucket_name`, `your_clean_bucket_name`, `your_curated_bucket_name`, and `your_report_bucket_name` with the actual names of your S3 buckets. 

## Exercise 4.1: Understanding Great Expectations
In this exercise, you will run the `main.py` script to execute raw validation against your data.
1. **Check and uncomment dependencies**:
   - Open the `tests/requirements.txt` file and ensure that the Great Expectations dependencies are not commented out. 

2. **Install dependencies**:
   - After ensuring the dependencies are uncommented, run the following command to install them:

   ```bash
   pip install -r tests/requirements.txt
   ```

3. **Navigate to the raw validation directory**:
   ```bash
   cd tests/great_expectations/raw_validation
   ```

4. **Run the main script**:
   ```bash
   python main.py
   ```

This will initiate the Great Expectations validation process for your raw data. Ensure that your AWS credentials are correctly configured to access the S3 bucket.

To view the results of your Great Expectations validation, you can open the index.html file generated by the Great Expectations data docs. This file is typically located in the uncommitted/data_docs/local_site/ directory of your project.

You can open it using your web browser by navigating to the following root path: `gx_raw_hospital_data_source/uncommitted/data_docs/local_site`



## Exercise 4.2: Adding Expectations to the Clean Layer

In this exercise, you will add expectations to validate the data in the clean layer. Before proceeding, check how your data looks in Athena to ensure that the structure aligns with your expectations.

1. **Review Data in Athena**:
   - Open the AWS Athena console and run queries to inspect the `clean_patients_data` and `clean_visits_data` tables. This will help you understand the data structure and identify any necessary expectations.

2. **Update the `CleanExpectationSuiteManager` class**:
   - Modify the `clean_expectation_suites.py` file to include two expectations for each asset in clean data source.

   ```python
   # tests/great_expectations/clean_validation/clean_expectation_suites.py

   #....  existing code ....
       def _add_patient_expectations(self):
           patient_expectations = [
               gxe.ExpectColumnValuesToNotBeNull(column="patient_id"),
               #TODO: Add here your expectations. You can check for available expectations at: [Expectations Gallery](https://greatexpectations.io/expectations/)
           ]
           for expectation in patient_expectations:
               self.patients_suite.add_expectation(expectation)

       def _add_visit_expectations(self):
           visit_expectations = [
               gxe.ExpectColumnValuesToNotBeNull(column="appointment_id"),
              #TODO: Add here your expectations. You can check for available expectations at: [Expectations Gallery](https://greatexpectations.io/expectations/)
           ]
           for expectation in visit_expectations:
               self.visits_suite.add_expectation(expectation)
   ```

3. **Navigate to the clean validation directory**:
   ```bash
   cd tests/great_expectations/clean_validation
   ```

4. **Run the main script**:
   ```bash
   python main.py
 

## Common Issues and Tips
- Ensure that your AWS credentials are correctly configured and have the necessary permissions to access the clean bucket.
- Double-check the data structure and expectations to ensure they align with your data source.


## Reference Solution

The final solution for all four exercises can be found in the `exercises_solution` folder. To use it, substitute the folders in the root directory with those in the solution folder and reexecute all steps from the first exercise.

Remember, it's best to try solving the exercise on your own first, but don't hesitate to use the reference solution if you need additional clarity or want to verify your approach.


## Key Takeaways

In this exercise, you've learned and practiced the following key concepts:

1. Implementing a new data source for the clean bucket.
2. Adding expectations to validate data quality.
3. Building and running checkpoints to ensure data integrity.